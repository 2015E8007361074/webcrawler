**我的网络爬虫学习笔记**

	Date：20160319
	Author:Wenyan Yu

学习Python除了为了进一步学习机器学习，进行相关算法的编写，还有一个重要的原因是我想用Python做网络爬虫开发。之前一直是想来着，但是一直没有行动，今日就要开始我的Python网络爬虫之旅啦，希望在接下来的学习过程中，我能够用Python去做一些有意思的东西！

继续我的爬虫学习之旅！ ---2017.01.03 By Wayne Yu

说句真心话，中关村的win10真的没有linux用的舒服，哎～～！---2017.01.03 By Wayne Yu

#### 关于陈娇娇同学的爬虫“小”程序（好想哭！~~~~~~~有点费时间了）

###### 主要目录两个cjj和data</br>
    1.cjj目录中的refactor_crawler.py是重构之后的最终版本，其余的文件是测试开发过程中写的，没兴趣可自动忽略，有兴趣跑跑也无妨。<br>
    2.data目录主要是用来存储爬取的数据：其中links.csv存储指定日期的所有拍卖商品详细页面URL，page_info.csv存储指定日期内所有拍卖商品的详细信息并以下面格式存储。<br>

标题，结束时间，拍卖状态，成交价格，报名人数，提醒人数，围观次数，起拍价，加价幅度，保证金，佣金，延时周期，保留价，送拍机构，特色服务<br>

###### 关于使用的问题
    首先要安装python3.4,python3.5,python3.6……(Python3.0以上的版本均可)，然后还需要安装BeautifulSoup4 python库。安装完这两项后就可运行本程序。<br>
    重构之后只有一个文件cjj/refactor_crawler.py<br>
    所有程序代码都封装成了一个类 Crawler,如果仅仅只是采集数据，类里里面的东西可以暂时不必理会，直接找到程序的入口:<br>
    if __name__ == "__main__":<br>

    需要采集那天的全部拍卖商品数据就往my_calendar_list列表中添加相应的URL,默认的只有2016年1月1日的URL,具体格式可以参照上面注释。




