**我的网络爬虫学习笔记**

	Date：20160319
	Author:Wenyan Yu

学习Python除了为了进一步学习机器学习，进行相关算法的编写，还有一个重要的原因是我想用Python做网络爬虫开发。之前一直是想来着，但是一直没有行动，今日就要开始我的Python网络爬虫之旅啦，希望在接下来的学习过程中，我能够用Python去做一些有意思的东西！

继续我的爬虫学习之旅！ ---2017.01.03 By Wayne Yu

说句真心话，中关村的win10真的没有linux用的舒服，哎～～！---2017.01.03 By Wayne Yu

由爬虫的学习到自自然语言处理，自然语言处理之旅即将开启，其实学习完爬虫能为自然语言处理提供很好的数据获取手段！---2017.03.08 By Wayne Yu

#### 关于陈娇娇同学的爬虫“小”程序（好想哭！~~~~~~~有点费时间了）

###### 主要目录两个cjj和data</br>
    1.cjj目录中的refactor_crawler.py是重构之后的最终版本,
    其余的文件是测试开发过程中写的，
    没兴趣可自动忽略，
    有兴趣跑跑也无妨。
    
    2.data目录主要是用来存储爬取的数据：
    其中links.csv存储指定日期的所有拍卖商品详细页面URL，
    page_info.csv存储指定日期内所有拍卖商品的详细信息并以下面格式存储,
    calendar_links.csv存储给定日期区间内拍卖商品的日历链接，每天对应一条记录。

标题，结束时间，拍卖状态，成交价格，报名人数，提醒人数，围观次数，起拍价，加价幅度，保证金，佣金，延时周期，保留价，送拍机构，特色服务<br>

    1.标题
    2.结束时间
    3.拍卖状态（已成交/流拍） 注：对于撤回和终止的拍卖商品，由于没有相关信息，对采集到页面予以舍弃，不进行抽取
    4.成交价格
    5.报名人数
    6.提醒人数
    7.围观次数
    8.起拍价
    9.加价幅度
    10.保证金
    11.佣金（没找到，默认为无）
    12.延时周期
    13.保留价（有或无）
    14.送拍机构（没找到默认为无）
    15.特色服务（没找到，默认为无）

###### 关于使用的问题
    首先要安装python3.4,python3.5,python3.6……(Python3.0以上的版本均可)，
    然后还需要安装BeautifulSoup4 python库。
    安装完这两项后就可运行本程序。
    重构之后只有一个文件cjj/refactor_crawler.py
    所有程序代码都封装成了一个类 Crawler,如果仅仅只是采集数据，类里里面的东西可以暂时不必理会，直接找到程序的入口:
    if __name__ == "__main__":
 
~~需要采集那天的全部拍卖商品数据就往my_calendar_list列表中添加相应的URL,~~
~~默认的只有2016年1月1日的URL,具体格式可以参照上面注释。~~

###### 给定时间段，自动采集数据的功能已添加完毕，使用方法按如下：

    找到程序入口：
    if __name__ == "__main__":
    你会发现下面代码，按照注释，给定好相应的时间区间，运行程序，即可自动采集对应时间段内的数据。
    # 开始采集的时间
    # 只需要填写年月日，如2016年1月1日->(2016,1,1,0,0,0)
    start_time = datetime.datetime(2016,1,1,0,0,0)
    # 结束采集的时间，要求同上
    end_time = datetime.datetime(2016,1,3,0,0,0)

2018年1月23日更新，jj2关于淘宝拍卖网Json API数据抓取的解决办法。


